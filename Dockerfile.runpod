# VantageVeoConverter RunPod Serverless Docker Image
FROM runpod/pytorch:2.0.1-py3.10-cuda11.8.0-devel-ubuntu22.04

# Metadata
LABEL maintainer="VantageVeoConverter"
LABEL description="AI Video Synchronizer + RIFE Interpolation for RunPod Serverless"
LABEL version="1.0.0"

# Environment variables for optimization
ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive
ENV PIP_NO_CACHE_DIR=1
ENV HF_HUB_ENABLE_HF_TRANSFER=1

# Set working directory
WORKDIR /app

# Install system dependencies in single layer
RUN apt-get update --yes --quiet && \
    apt-get install --yes --quiet --no-install-recommends \
    # Basic build tools
    build-essential \
    cmake \
    git \
    wget \
    curl \
    unzip \
    # Audio/Video processing
    ffmpeg \
    libavcodec-dev \
    libavformat-dev \
    libswscale-dev \
    # Audio alignment dependencies
    libespeak-dev \
    espeak \
    espeak-data \
    # Additional system libs
    libsndfile1 \
    libgomp1 \
    # Cleanup in same layer to reduce image size
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# mp4fpsmod will be installed from bin/ directory (see below)

# Copy requirements and install Python dependencies
COPY requirements.txt /app/requirements.txt

# Upgrade pip and install build tools
RUN pip install --upgrade pip wheel setuptools

# CRITICAL: Install specific setuptools version for aeneas compatibility
RUN pip install "setuptools==59.5.0"

# Install core numerical libraries first
RUN pip install "numpy>=1.24,<2.3" "scipy>=1.9.0"

# Install PyTorch suite (use RunPod's pre-installed version if available)
RUN pip install "torch>=1.12.0" "torchvision>=0.13.0" "torchaudio>=0.12.0" \
    --index-url https://download.pytorch.org/whl/cu118 || \
    echo "Using pre-installed PyTorch from RunPod base image"

# Install RunPod SDK
RUN pip install "runpod>=1.0.0"

# Install main application dependencies
RUN pip install \
    "opencv-python>=4.5.0" \
    "scikit-image>=0.19.0" \
    "openai-whisper>=20230314" \
    "librosa>=0.9.0" \
    "tqdm>=4.64.0" \
    "Pillow>=9.0.0" \
    "requests>=2.25.0" \
    "numba>=0.56.0" \
    "psutil>=5.8.0" \
    "ffmpeg-python>=0.2.0" \
    "boto3>=1.26.0"

# Install aeneas with multiple strategies (REQUIRED for audio sync)
RUN echo "Installing aeneas (REQUIRED for audio synchronization)..." && \
    # Strategy 1: Try with no-build-isolation
    (pip install --no-build-isolation "aeneas>=1.7.3" && echo "✅ aeneas installed via no-build-isolation") || \
    # Strategy 2: Try from git repository
    (pip install "git+https://github.com/readbeyond/aeneas.git" && echo "✅ aeneas installed from git") || \
    # Strategy 3: Try with older setuptools
    (pip install "setuptools==58.0.0" && pip install "aeneas>=1.7.3" && echo "✅ aeneas installed with older setuptools") || \
    # Strategy 4: Try specific version
    (pip install "aeneas==1.7.3.0" && echo "✅ aeneas specific version installed") || \
    # Strategy 5: Try with build dependencies
    (apt-get update && apt-get install -y python3-dev cython3 && pip install "aeneas" && echo "✅ aeneas installed with build deps") || \
    # FAIL: aeneas is critical
    (echo "❌ CRITICAL: aeneas installation failed - audio sync will not work!" && exit 1)

# Create directories for models and bins
RUN mkdir -p /app/bin /app/weights /app/src

# Copy application files
COPY src/ /app/src/
COPY weights/ /app/weights/
COPY runpod_handler.py /app/
COPY install_dependencies.py /app/

# Copy binary files if they exist (optional)
COPY bin/ /app/bin/

# Set permissions
RUN chmod +x /app/bin/* 2>/dev/null || true
RUN chmod +x /app/runpod_handler.py

# Add /app/bin to PATH for runtime
ENV PATH="/app/bin:$PATH"

# Pre-download common models to reduce cold start time
RUN python -c "import whisper; whisper.load_model('base')" || echo "Whisper download failed, will download at runtime"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import torch; import runpod; print('Container healthy')" || exit 1

# Expose port for local testing (RunPod handles this automatically)
EXPOSE 8080

# Set the command to run the handler
CMD ["python", "-u", "/app/runpod_handler.py"]