"""
RIFE AI Engine for frame interpolation - Updated to use PyTorch RIFE
"""
import logging
import torch
import torch.nn.functional as F
import cv2
import numpy as np
import subprocess
import sys
from .optical_flow_rife import OpticalFlowRIFE

class RealRIFE:
    """Real RIFE AI model for frame interpolation - Optical Flow implementation."""
    
    def __init__(self, device="cuda"):
        self.device = device if torch.cuda.is_available() else "cpu"
        self.available = False
        self.method = "optical_flow_rife"
        self.optical_flow_rife = None
        self._setup_rife()
    
    def _setup_rife(self):
        """Setup Optical Flow RIFE AI model."""
        try:
            logging.info("ü§ñ Setting up Optical Flow RIFE AI model...")
            
            # Initialize Optical Flow RIFE
            self.optical_flow_rife = OpticalFlowRIFE(self.device)
            
            if self.optical_flow_rife.available:
                self.method = "optical_flow_rife"
                self.available = True
                logging.info("‚úÖ Optical Flow RIFE ready! (NO BLENDING)")
            else:
                self.method = "enhanced_cv" 
                self.available = False
                logging.info("‚ö†Ô∏è Optical Flow RIFE failed, using enhanced fallback")
                
        except Exception as e:
            logging.error(f"‚ùå Optical Flow RIFE setup failed: {e}")
            self.method = "simple"
            self.available = False
            
        logging.info(f"üéØ Final RIFE method: {self.method.upper()}")
        try:
            if torch.cuda.is_available():
                gpu_props = torch.cuda.get_device_properties(0)
                logging.info(f"üöÄ GPU: {torch.cuda.get_device_name(0)}")
                logging.info(f"üíæ GPU Memory available: {gpu_props.total_memory // 1024**3} GB")
                logging.info(f"üî• GPU ready for accelerated interpolation!")
                
                # Clear any cached memory
                torch.cuda.empty_cache()
            else:
                logging.info("‚ö†Ô∏è  No GPU available, using CPU")
        except Exception as e:
            logging.warning(f"Could not get GPU info: {e}")
    
    # Old setup function removed - using PyTorch RIFE now
    
    def interpolate_frames(self, frame1, frame2, num_intermediate=1):
        """Real Optical Flow RIFE interpolation - NO BLENDING."""
        try:
            # Use Optical Flow RIFE if available
            if self.method == "optical_flow_rife" and self.optical_flow_rife and self.optical_flow_rife.available:
                return self.optical_flow_rife.interpolate_frames(frame1, frame2, num_intermediate)
            elif self.method == "enhanced_cv":
                return self._enhanced_interpolation(frame1, frame2, num_intermediate)
            else:
                return self._simple_interpolation(frame1, frame2, num_intermediate)
            
        except Exception as e:
            logging.warning(f"Optical Flow RIFE interpolation failed, using fallback: {e}")
            return self._simple_interpolation(frame1, frame2, num_intermediate)
    
    # Old RIFE functions removed - using PyTorch RIFE now

    def _enhanced_interpolation(self, frame1, frame2, num_intermediate):
        """Enhanced GPU-accelerated interpolation with duplicate frame handling."""
        try:
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Convert frames to tensors
            def frame_to_tensor(frame):
                # Convert BGR to RGB, normalize to [0,1]
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                tensor = torch.from_numpy(frame_rgb).float() / 255.0
                tensor = tensor.permute(2, 0, 1).unsqueeze(0).to(device)  # NCHW format
                return tensor
            
            frame1_tensor = frame_to_tensor(frame1)
            frame2_tensor = frame_to_tensor(frame2)
            
            # Check if frames are identical or very similar
            diff = frame2_tensor - frame1_tensor
            frame_similarity = torch.mean(torch.abs(diff)).item()
            
            interpolated_frames = []
            
            with torch.no_grad():
                for i in range(1, num_intermediate + 1):
                    timestep = i / (num_intermediate + 1)
                    
                    if frame_similarity < 0.01:
                        # Frames are nearly identical - create subtle variations
                        logging.debug(f"Creating subtle variations for identical frames (similarity: {frame_similarity:.4f})")
                        
                        # Apply subtle transformations to create motion illusion
                        t_smooth = torch.tensor(timestep, device=device)
                        
                        # Create subtle brightness oscillation
                        brightness_factor = 1.0 + 0.02 * torch.sin(t_smooth * 3.14159)
                        
                        # Create subtle contrast variation  
                        contrast_factor = 1.0 + 0.01 * torch.cos(t_smooth * 3.14159)
                        
                        # Apply subtle color temperature shift
                        temp_shift = 0.005 * torch.sin(t_smooth * 6.28318)
                        
                        # Base interpolated frame
                        base_frame = frame1_tensor * (1 - timestep) + frame2_tensor * timestep
                        
                        # Apply subtle enhancements
                        enhanced = base_frame * brightness_factor * contrast_factor
                        
                        # Add slight color temperature variation
                        enhanced[:, 0, :, :] += temp_shift  # Red channel
                        enhanced[:, 2, :, :] -= temp_shift * 0.5  # Blue channel
                        
                        # Clamp to valid range
                        enhanced = torch.clamp(enhanced, 0, 1)
                        
                        # Convert back to numpy
                        result_tensor = enhanced.squeeze(0).permute(1, 2, 0)
                        result_rgb = (result_tensor * 255).byte().cpu().numpy()
                        result_bgr = cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR)
                        
                        interpolated_frames.append(result_bgr)
                        
                    else:
                        # Standard motion interpolation
                        try:
                            # Apply temporal smoothing
                            t_smooth = torch.tensor(timestep, device=device)
                            t_curve = 3 * t_smooth**2 - 2 * t_smooth**3  # Smooth curve
                            
                            # Enhanced interpolation with motion-aware blending
                            interpolated = frame1_tensor + diff * t_curve
                            
                            # Add slight blur for smoothness if high motion detected
                            motion_magnitude = torch.mean(torch.abs(diff))
                            if motion_magnitude > 0.1:
                                # Apply gaussian blur for high-motion areas
                                kernel_size = 3
                                sigma = 0.3
                                interpolated = F.gaussian_blur(interpolated, kernel_size, sigma)
                            elif motion_magnitude > 0.05:
                                # Light blur for medium motion
                                kernel_size = 3
                                sigma = 0.1
                                interpolated = F.gaussian_blur(interpolated, kernel_size, sigma)
                            
                            # Convert back to numpy
                            result_tensor = interpolated.squeeze(0).permute(1, 2, 0)
                            result_rgb = (result_tensor.clamp(0, 1) * 255).byte().cpu().numpy()
                            result_bgr = cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR)
                            
                            interpolated_frames.append(result_bgr)
                            
                        except Exception as gpu_e:
                            logging.debug(f"GPU motion interpolation failed: {gpu_e}")
                            # Fallback to basic blending
                            blended_tensor = frame1_tensor * (1 - timestep) + frame2_tensor * timestep
                            result_tensor = blended_tensor.squeeze(0).permute(1, 2, 0)
                            result_rgb = (result_tensor.clamp(0, 1) * 255).byte().cpu().numpy()
                            result_bgr = cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR)
                            interpolated_frames.append(result_bgr)
            
            return interpolated_frames
            
        except Exception as e:
            logging.warning(f"GPU-enhanced interpolation failed: {e}")
            return self._simple_interpolation(frame1, frame2, num_intermediate)
    
    def _simple_interpolation(self, frame1, frame2, num_intermediate):
        """Reliable OpenCV interpolation."""
        interpolated_frames = []
        for i in range(1, num_intermediate + 1):
            alpha = i / (num_intermediate + 1)
            blended = cv2.addWeighted(frame1, 1-alpha, frame2, alpha, 0)
            interpolated_frames.append(blended)
        return interpolated_frames