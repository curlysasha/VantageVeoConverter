"""
Simple and reliable frame interpolation system
Rewritten from scratch for stability and quality
"""
import cv2
import numpy as np
import torch
import torch.nn.functional as F
import logging
from typing import List, Tuple, Optional

class SimpleFrameInterpolator:
    """Simple, reliable frame interpolator focused on quality over complexity."""
    
    def __init__(self, device="cuda"):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.use_gpu = torch.cuda.is_available() and device == "cuda"
        
        logging.info(f"üé¨ Frame interpolator initialized on {self.device}")
        if self.use_gpu:
            logging.info(f"üöÄ GPU acceleration enabled")
    
    def detect_duplicate_frames(self, frames: List[np.ndarray], threshold: float = 0.02) -> List[int]:
        """
        Detect duplicate frames using simple pixel difference.
        Returns list of frame indices that are duplicates.
        """
        duplicates = []
        
        logging.info(f"üîç Analyzing {len(frames)} frames for duplicates...")
        
        for i in range(1, len(frames)):
            # Simple pixel difference
            diff = cv2.absdiff(frames[i-1], frames[i])
            mean_diff = np.mean(diff) / 255.0
            
            if mean_diff < threshold:
                duplicates.append(i)
            
            if i % 100 == 0:
                logging.info(f"   Progress: {i}/{len(frames)} frames analyzed")
        
        duplicate_pct = len(duplicates) / len(frames) * 100
        logging.info(f"üìä Found {len(duplicates)} duplicate frames ({duplicate_pct:.1f}%)")
        
        return duplicates
    
    def create_interpolated_frame(self, frame1: np.ndarray, frame2: np.ndarray, 
                                 alpha: float = 0.5) -> np.ndarray:
        """
        Create a single interpolated frame between two frames.
        Alpha: 0.0 = frame1, 1.0 = frame2, 0.5 = middle
        """
        if self.use_gpu:
            return self._gpu_interpolate(frame1, frame2, alpha)
        else:
            return self._cpu_interpolate(frame1, frame2, alpha)
    
    def _cpu_interpolate(self, frame1: np.ndarray, frame2: np.ndarray, alpha: float) -> np.ndarray:
        """CPU-based simple blending."""
        # Simple weighted blend
        result = cv2.addWeighted(frame1, 1-alpha, frame2, alpha, 0)
        return result
    
    def _gpu_interpolate(self, frame1: np.ndarray, frame2: np.ndarray, alpha: float) -> np.ndarray:
        """GPU-accelerated interpolation with motion compensation."""
        try:
            # Convert to tensors
            def to_tensor(frame):
                tensor = torch.from_numpy(frame).float().to(self.device) / 255.0
                return tensor.permute(2, 0, 1).unsqueeze(0)  # NCHW
            
            tensor1 = to_tensor(frame1)
            tensor2 = to_tensor(frame2)
            
            with torch.no_grad():
                # Check if frames are very similar
                diff = torch.mean(torch.abs(tensor2 - tensor1)).item()
                
                if diff < 0.02:  # Very similar frames
                    # Create subtle variation to avoid exact duplication
                    alpha_smooth = torch.tensor(alpha, device=self.device)
                    
                    # Apply smooth curve for natural transition
                    curve = 3 * alpha_smooth**2 - 2 * alpha_smooth**3
                    
                    # Basic interpolation
                    result = tensor1 * (1 - curve) + tensor2 * curve
                    
                    # Add very subtle noise for variation
                    if alpha != 0.0 and alpha != 1.0:
                        noise_strength = 0.005 * torch.sin(alpha_smooth * 3.14159)
                        noise = torch.randn_like(result) * noise_strength
                        result = result + noise
                    
                else:  # Different frames - use motion-aware blending
                    # Apply temporal smoothing curve
                    alpha_smooth = torch.tensor(alpha, device=self.device)
                    curve = 3 * alpha_smooth**2 - 2 * alpha_smooth**3
                    
                    # Interpolate
                    result = tensor1 * (1 - curve) + tensor2 * curve
                    
                    # Apply slight blur for motion smoothness
                    if diff > 0.1:  # High motion
                        result = F.gaussian_blur(result, kernel_size=3, sigma=0.5)
                
                # Convert back to numpy
                result = torch.clamp(result, 0, 1)
                result_np = result.squeeze(0).permute(1, 2, 0).cpu().numpy()
                result_np = (result_np * 255).astype(np.uint8)
                
                return result_np
                
        except Exception as e:
            logging.warning(f"GPU interpolation failed: {e}, falling back to CPU")
            return self._cpu_interpolate(frame1, frame2, alpha)
    
    def process_video_simple(self, input_path: str, output_path: str, 
                           duplicate_threshold: float = 0.02) -> dict:
        """
        Simple video processing: find duplicates and replace with interpolated frames.
        
        Strategy:
        1. Load all frames
        2. Find duplicate frames  
        3. Replace each duplicate with interpolation between nearest non-duplicates
        4. Write result
        """
        logging.info(f"üé¨ Starting simple video interpolation")
        logging.info(f"   Input: {input_path}")
        logging.info(f"   Output: {output_path}")
        
        # Load video
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logging.info(f"üìπ Video info: {total_frames} frames, {fps} FPS, {width}x{height}")
        
        # Load all frames
        logging.info("üìÇ Loading all frames...")
        frames = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame)
        cap.release()
        
        logging.info(f"‚úÖ Loaded {len(frames)} frames")
        
        # Find duplicates
        duplicates = self.detect_duplicate_frames(frames, duplicate_threshold)
        
        if not duplicates:
            logging.info("‚ÑπÔ∏è  No duplicates found, copying original video")
            import shutil
            shutil.copy2(input_path, output_path)
            return {"duplicates_found": 0, "duplicates_replaced": 0}
        
        # Create output video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        replaced_count = 0
        
        try:
            logging.info(f"üîÑ Processing {len(frames)} frames...")
            
            for i in range(len(frames)):
                if i in duplicates:
                    # This is a duplicate frame - replace it
                    
                    # Find previous non-duplicate frame
                    prev_idx = i - 1
                    while prev_idx >= 0 and prev_idx in duplicates:
                        prev_idx -= 1
                    
                    # Find next non-duplicate frame  
                    next_idx = i + 1
                    while next_idx < len(frames) and next_idx in duplicates:
                        next_idx += 1
                    
                    if prev_idx >= 0 and next_idx < len(frames):
                        # Interpolate between prev and next non-duplicate frames
                        distance = next_idx - prev_idx
                        position = i - prev_idx
                        alpha = position / distance if distance > 0 else 0.5
                        
                        interpolated = self.create_interpolated_frame(
                            frames[prev_idx], frames[next_idx], alpha
                        )
                        out.write(interpolated)
                        replaced_count += 1
                        
                        if replaced_count % 10 == 0:
                            logging.info(f"   üîÑ Replaced {replaced_count} duplicates so far")
                    
                    elif prev_idx >= 0:
                        # Only previous frame available - use slight variation
                        variation = self._create_slight_variation(frames[prev_idx])
                        out.write(variation)
                        replaced_count += 1
                    
                    elif next_idx < len(frames):
                        # Only next frame available - use slight variation
                        variation = self._create_slight_variation(frames[next_idx]) 
                        out.write(variation)
                        replaced_count += 1
                    
                    else:
                        # No other frames available - use original
                        out.write(frames[i])
                
                else:
                    # Normal frame - use as is
                    out.write(frames[i])
                
                # Progress logging
                if i % 50 == 0:
                    progress = (i / len(frames)) * 100
                    logging.info(f"   Progress: {progress:.1f}%")
        
        finally:
            out.release()
        
        # Results
        duplicate_pct = len(duplicates) / len(frames) * 100
        replaced_pct = replaced_count / len(frames) * 100
        
        logging.info(f"‚úÖ Interpolation complete!")
        logging.info(f"üìä Results:")
        logging.info(f"   ‚Ä¢ Found {len(duplicates)} duplicate frames ({duplicate_pct:.1f}%)")
        logging.info(f"   ‚Ä¢ Replaced {replaced_count} frames ({replaced_pct:.1f}%)")
        logging.info(f"   ‚Ä¢ Output: {output_path}")
        
        return {
            "duplicates_found": len(duplicates),
            "duplicates_replaced": replaced_count,
            "total_frames": len(frames),
            "duplicate_percentage": duplicate_pct,
            "replaced_percentage": replaced_pct
        }
    
    def _create_slight_variation(self, frame: np.ndarray) -> np.ndarray:
        """Create a slight variation of a frame to avoid exact duplication."""
        if self.use_gpu:
            try:
                # GPU-based variation
                tensor = torch.from_numpy(frame).float().to(self.device) / 255.0
                
                # Add very subtle noise
                noise = torch.randn_like(tensor) * 0.003
                varied = tensor + noise
                varied = torch.clamp(varied, 0, 1)
                
                result = (varied.cpu().numpy() * 255).astype(np.uint8)
                return result
            except:
                pass
        
        # CPU fallback - very subtle random noise
        noise = np.random.randint(-2, 3, frame.shape, dtype=np.int8)
        result = cv2.add(frame, noise.astype(frame.dtype))
        return result